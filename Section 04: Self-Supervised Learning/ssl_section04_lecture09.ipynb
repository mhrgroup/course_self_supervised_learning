{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ssl_section04_lecture09.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mhrgroup/course_self_supervised_learning/blob/main/Section%2004%3A%20Self-Supervised%20Learning/ssl_section04_lecture09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lecture 09: SimCLR, An UnSupervised Contrastive Pretext Model**\n",
        "\n",
        "By the end of this lecture, you will be able to:\n",
        "\n",
        "1. Describe how SimCLR of [Chen et al. (2020)](http://proceedings.mlr.press/v119/chen20j/chen20j.pdf) works.\n",
        "2. Develop SimCLR custom loss and training functions."
      ],
      "metadata": {
        "id": "Wt9jAeTSiWju"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **9.1. Pretext SimCLR**\n",
        "---\n",
        "* [Chen et al. (2020)](http://proceedings.mlr.press/v119/chen20j/chen20j.pdf) proposed a machine learning framework model for contrastive learning of visual representation (SimCLR).\n",
        "* This unsupervised contrastive model showed a notable accuracy boost on various standard visual data benchmarks such as CIFAR10, CIFAR100, and Caltech-101 after fine-tuning.\n",
        "* SimCLR model is composed of a multi-layer encoder, also referred to as the regressor, and a usually shallow neural network (i.e., dense layers) projector.\n",
        "* The encoder is later transferred for the downstream task.\n",
        "* The SimCLR model enriches pretext models by maximizing the agreement between pairs of augmentations’ representations and marginalizing the representations from augmentations of other data points in a batch.\n",
        "* The idea is not limited to visual data and can be applied to data types such as temporal records.\n",
        "* The following Figure shows the [Chen et al. (2020)](http://proceedings.mlr.press/v119/chen20j/chen20j.pdf) SimCLR pretext model along with a downstream classification model.\n",
        "\n",
        "> <img src=\t\"https://raw.githubusercontent.com/mhrgroup/course_self_supervised_learning/main/images/simclr1.png\"\twidth=\"500\"/>\n",
        "\n",
        "\n",
        "* The SimCLR superiority is because of\n",
        " * Using two augmentations instead of one to retrieve enricher feature representations in the encoder (last encoder’s hidden layer in Figure), and\n",
        " * Using a simple projector to obtain a profound transformation of the encoder’s representation for pretext task.\n",
        "\n",
        "* In a training batch, for a particular data point, the SimCLR’s loss function increases augmentation representations’ proximity while marginalizing these representations from other data points’ augmentation's representations.\n",
        "\n",
        "> <img src=\t\"https://raw.githubusercontent.com/mhrgroup/course_self_supervised_learning/main/images/simclralgorithm0.png\"\twidth=\"400\"/>\n"
      ],
      "metadata": {
        "id": "KYputyuB5QCx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **9.2. SimCLR Loss Loss and Training Functions**\n",
        "\n",
        "---\n",
        "\n",
        "* We first create a custom loss function.\n",
        "* Next, we create a SimCLR training function.\n"
      ],
      "metadata": {
        "id": "wFx-rm9eemuR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **9.2.1. Loss Function**\n",
        "\n",
        "* Custom loss functions in TensorFlow require two inputs, real and estimated output values.\n",
        "\n",
        "* SimCLR is an unsupervised model, so we create some dummy real output values with the same shape as the predicted ones.  \n",
        "\n",
        "* The estimated output values are the projector's representation, denoted as z_estimate.\n",
        "\n",
        "* Remember if N is the batch size the size of matrix z_real is 2*N.\n",
        "\n",
        "* Our goal is to avoid \"for loops\" in loss and benefit from multi-threading and memory for training speed.\n",
        "\n",
        "* The custom loss functions should be written in the tensor format using the TensorFlow library.\n",
        "\n",
        "> **Abbreviations:**\n",
        "*\tdatain: input data\n",
        "*\tind: index\n",
        "* tf: tensorflow"
      ],
      "metadata": {
        "id": "z_6chqYEw0jG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import necessary libraries\n",
        "import tensorflow as tf\n",
        "# tqdm provides a simple and convenient way to add progress bars to loops.\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "0XLELvR3oSeI",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Custom loss function\n",
        "# Updated on 20240506 for TensorFlow 2.15.0\n",
        "@tf.function\n",
        "def fun_simclr_loss(z_real, z_estimate):\n",
        "    # The z_real parameter is not used since SimCLR is an unsupervised model.\n",
        "    # This dummy variable is discarded.\n",
        "    del z_real\n",
        "\n",
        "    # Temperature parameter is set to 0.1. This hyperparameter can be tuned\n",
        "    # for specific problems to control the smoothness of the output distribution.\n",
        "    toe = .1\n",
        "\n",
        "    # Calculate the number of projections, which is twice the batch size (2N).\n",
        "    num = z_estimate.shape[0]\n",
        "\n",
        "    # Generate two sets of indices for all possible pair combinations within the batch.\n",
        "    # ind0 is a temporary variable holding the repeated range for generating indices.\n",
        "    ind0 = tf.repeat(tf.expand_dims(tf.range(0, num), axis=0), num, axis=0)\n",
        "    # Flatten ind0 to create a single list of indices for the first element of pairs.\n",
        "    ind1 = tf.reshape(ind0, (num**2, 1))[:, 0]\n",
        "    # Flatten the transpose of ind0 to create a single list of indices for the second element of pairs.\n",
        "    ind2 = tf.reshape(tf.transpose(ind0), (num**2, 1))[:, 0]\n",
        "\n",
        "    # The temporary index tensor is no longer needed after use.\n",
        "    del ind0\n",
        "\n",
        "    # Select the projections based on the first set of indices to form the first elements of pairs.\n",
        "    vector_1 = tf.gather(z_estimate, ind1, axis=0)\n",
        "    # The first set of indices is no longer needed after use.\n",
        "    del ind1\n",
        "\n",
        "    # Select the projections based on the second set of indices to form the second elements of pairs.\n",
        "    vector_2 = tf.gather(z_estimate, ind2, axis=0)\n",
        "    # The second set of indices is no longer needed after use.\n",
        "    del ind2\n",
        "\n",
        "    # Calculate the cosine similarity between each pair of projections and negate it to prepare for loss calculation.\n",
        "    s = -tf.reshape(tf.keras.losses.cosine_similarity(vector_1, vector_2, axis=1), (num, num))\n",
        "\n",
        "    # The vector tensors are no longer needed after computing similarities.\n",
        "    del vector_1\n",
        "    del vector_2\n",
        "\n",
        "    # Calculate the nominator of the contrastive loss function for each pair.\n",
        "    nom = tf.exp(s / toe)\n",
        "\n",
        "    # Calculate the denominator of the contrastive loss function by excluding the self-similarity term.\n",
        "    x1 = tf.exp(s / toe)\n",
        "    x2 = 1 - tf.eye(num, dtype=tf.float32)\n",
        "    denom = tf.repeat(tf.expand_dims(tf.math.reduce_sum(x1 * x2, axis=1), axis=1), num, axis=1)\n",
        "\n",
        "    # The intermediate tensors used for the denominator are no longer needed.\n",
        "    del s\n",
        "    del x1\n",
        "    del x2\n",
        "\n",
        "    # Calculate the loss `l(i, j)` for each pair of projections using the computed nominator and denominator.\n",
        "    l = -tf.math.log(nom / denom)\n",
        "\n",
        "    # Cleanup intermediate tensors to save memory.\n",
        "    del nom\n",
        "    del denom\n",
        "\n",
        "    # Prepare indices to extract the diagonal elements from the loss matrix, which correspond to the actual pair losses.\n",
        "    ind_2k0 = tf.range(0, num, 2, dtype=tf.int32)  # Even indices\n",
        "    ind_2k1 = tf.range(1, num, 2, dtype=tf.int32)  # Odd indices\n",
        "\n",
        "    # Extract and sum the losses for the actual pairs using the prepared indices.\n",
        "    loss_mat1_1 = tf.gather(l, ind_2k0, axis=0)\n",
        "    loss_mat1_2 = tf.gather(loss_mat1_1, ind_2k1, axis=1)\n",
        "    loss_mat1 = tf.linalg.diag_part(loss_mat1_2)\n",
        "\n",
        "    loss_mat2_1 = tf.gather(l, ind_2k1, axis=0)\n",
        "    loss_mat2_2 = tf.gather(loss_mat2_1, ind_2k0, axis=1)\n",
        "    loss_mat2 = tf.linalg.diag_part(loss_mat2_2)\n",
        "\n",
        "    # After extracting the necessary elements, the large loss tensor can be discarded.\n",
        "    del l\n",
        "\n",
        "    # Combine the individual loss components into a single tensor.\n",
        "    loss_mat = loss_mat1 + loss_mat2\n",
        "\n",
        "    # Compute the final loss by taking the sum over all individual losses and normalizing by the number of pairs.\n",
        "    L = tf.math.reduce_sum(loss_mat) / num\n",
        "\n",
        "\n",
        "    # Return the final computed loss.\n",
        "    return L"
      ],
      "metadata": {
        "id": "KYASeSUfoX_x",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title SimCLR training function\n",
        "# Updated on 20240506 for TensorFlow 2.15.0\n",
        "# At the records of the videos, we had TensorFlow version 2.9.0.\n",
        "# The latest version of TensorFlow is 2.15.0 as of 20240506. As such, we updated\n",
        "# our code significantly to increase its efficiency and make it aligned with\n",
        "# TesnorFlow version 2.15.0. The code is commented on so that students can\n",
        "# study the updates.\n",
        "\n",
        "def fun_train_simclr(model, images, fun_augment_01, fun_augment_02,\n",
        "                     epochs=100, batch_size = 16, verbose=1, patience=3, learning_rate=0.001):\n",
        "\n",
        "    # Determine the output size of the model's last layer\n",
        "    z_size = model.layers[-1].weights[-1].shape[0]\n",
        "\n",
        "    # Initialize a list to keep track of the loss values for each epoch\n",
        "    loss = []\n",
        "\n",
        "    # Initialize the optimizer with the specified learning rate\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    # Create a TensorFlow Dataset\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(images)\n",
        "    dataset = dataset.shuffle(buffer_size=10000)  # Adjust buffer size to your dataset size/available memory\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.cache()  # Cache the data to avoid re-reading from disk/memory each epoch\n",
        "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)  # Prefetch batches in the background\n",
        "\n",
        "    # Loop through each epoch\n",
        "    for epoch in range(epochs):\n",
        "        # Initialize a variable to keep track of the running loss for the current epoch\n",
        "        loss_running = 0\n",
        "\n",
        "        # Initialize a progress bar using tqdm to visualize training progress\n",
        "        pbar = tqdm(dataset,\n",
        "                    desc  = f\"SimCLR Training: {epoch + 1:03d}/{epochs}\", # Description shown in the progress bar\n",
        "                    ncols = 125, # Width of the progress bar\n",
        "                    leave = True) # Whether the progress bar should remain after completion\n",
        "\n",
        "        # Iterate over each batch in the dataset\n",
        "        for batch_num, batch in enumerate(pbar, 1):\n",
        "            if isinstance(batch, tuple):\n",
        "                batch_in = batch[0] # Get the input data from the batch\n",
        "            else:\n",
        "                batch_in = batch\n",
        "\n",
        "            # Apply two different augmentations to the input data\n",
        "            x_tilda_01 = fun_augment_01(batch_in)\n",
        "            x_tilda_02 = fun_augment_02(batch_in)\n",
        "\n",
        "            # Concatenate the augmented data along the batch axis and reshape it for the model input\n",
        "            x_tilda = tf.reshape(tf.concat([x_tilda_01, x_tilda_02], axis=0),\n",
        "                                (x_tilda_01.shape[0] * 2, # Corrected to ensure the correct shape for concatenation\n",
        "                                 x_tilda_01.shape[1], x_tilda_01.shape[2],\n",
        "                                 x_tilda_01.shape[3]))\n",
        "\n",
        "            # Create a dummy output tensor of the same size as the model's output\n",
        "            z_real = tf.random.uniform((x_tilda.shape[0], z_size))\n",
        "\n",
        "            # Open a GradientTape to record the operations for automatic differentiation\n",
        "            with tf.GradientTape() as tape:\n",
        "                # Pass the concatenated and augmented inputs through the model\n",
        "                z_estimate = model(x_tilda, training=True)\n",
        "\n",
        "                # Calculate the batch loss using the custom SimCLR loss function\n",
        "                loss_batch = fun_simclr_loss(z_real, z_estimate)\n",
        "\n",
        "            # Calculate the gradients of the loss with respect to the model's trainable variables\n",
        "            gradients = tape.gradient(loss_batch, model.trainable_variables)\n",
        "\n",
        "            # Apply the calculated gradients to the model's variables to minimize the loss\n",
        "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "            # Update the running loss for the epoch\n",
        "            loss_running += loss_batch.numpy()  # Ensure loss is a scalar by calling .numpy()\n",
        "\n",
        "            # If verbose, update the progress bar with the current average loss\n",
        "            if verbose:\n",
        "                pbar.set_postfix(loss = f\"{loss_running/batch_num:.6f}\")\n",
        "\n",
        "        # Append the average loss for this epoch to the loss history\n",
        "        loss.append(loss_running / batch_num)\n",
        "\n",
        "        # Check for early stopping: if there's no improvement in loss for a specified number of epochs, stop training\n",
        "        if epoch >= patience:\n",
        "            if loss[-1] > min(loss[:-patience]):\n",
        "                print(\"Early stopping due to no improvement in loss.\")\n",
        "                break  # Exit the training loop\n",
        "\n",
        "    # Return the trained model and the history of loss values\n",
        "    return model, loss"
      ],
      "metadata": {
        "cellView": "form",
        "id": "KydJ9JczvNvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lecture 09: SimCLR, An UnSupervised Contrastive Model**\n",
        "\n",
        "In this lecture, you learned about:\n",
        "\n",
        "1. How SimCLR of [Chen et al. (2020)](http://proceedings.mlr.press/v119/chen20j/chen20j.pdf) works.\n",
        "2. SimCLR custom loss and training functions.\n",
        "\n",
        "> ***In the following lecture, we will see a labeling example using SimCLR unsupervised contrastive learning.***"
      ],
      "metadata": {
        "id": "bBiYNuP3LRf-"
      }
    }
  ]
}