{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ssl_section04_lecture08.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mhrgroup/course_self_supervised_learning/blob/main/Section%2004%3A%20Self-Supervised%20Learning/ssl_section04_lecture08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lecture 08: Supervised Contrastive Pretext, Experiment 2**\n",
        "\n",
        "By the end of this lecture, you will be able to:\n",
        "\n",
        "1. Address a labeling problem with supervised contrastive pretext with pretrained parameters."
      ],
      "metadata": {
        "id": "Wt9jAeTSiWju"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8.1. Experiment 2**\n",
        "---\n",
        "* This experiment is similar to the previous one!\n",
        "* We assume only 1000 training images are labeled in CIFAR-10.\n",
        "* We develop a supervised contrastive pretext (prx) model using all training inputs and fine-tune it on the 1000 labeled images in the downstream (dwm) task.\n",
        "* We then label the testing images using the fine-tuned model.\n",
        "* We assume that there is a trained network on similar data distribution. Hence, our model has pretrained parameters.\n",
        "* We compare this model with the result of a fairly similar fully supervised (fsp) model trained on the 1000 labeled data.\n",
        "* Note: we have to develop three models here, model_fsp, model_prx, and model_dwm.\n",
        "\n",
        "> **Abbreviations:**\n",
        "* acc: accuracy\n",
        "*\tdatain: input data\n",
        "*\tdataou: output data\n",
        "*\tdwm: downstream\n",
        "*\tfnt: fine-tuning\n",
        "*\tfsp: fully supervised learning\n",
        "* lr: learning rate\n",
        "*\tprx: pretext\n",
        "*\tte: testing\n",
        "*\ttf: tensorflow\n",
        "*\ttr: training\n",
        "*\ttrf: transfer learning"
      ],
      "metadata": {
        "id": "SFe73rDdh8yt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install necessary libraries & restart the session\n",
        "\n",
        "# Install the required libraries using the `pip` package manager.\n",
        "!pip install tensorflow==2.15\n",
        "\n",
        "# Import the time module to add a delay before restarting the session.\n",
        "import time\n",
        "\n",
        "# Import `clear_output` from IPython to clear the notebook output, ensuring a clean display for the user.\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Clear the output after the packages are installed to make the notebook cleaner.\n",
        "clear_output()\n",
        "\n",
        "# Print a message to let the user know that the libraries are installed & the session will restart.\n",
        "print(\"Necessary Libraries are Installed. Restarting the session!\")\n",
        "\n",
        "# Add a short delay (1 second) before restarting to allow the message to be displayed to the user.\n",
        "time.sleep(1)\n",
        "\n",
        "# Import the `os` module to access low-level operating system functionality.\n",
        "import os\n",
        "\n",
        "# Use `os._exit(00)` to exit the current Python runtime environment forcefully.\n",
        "# This effectively simulates a restart in notebook environments like Google Colab or Jupyter.\n",
        "# After this command, the environment will be restarted & all the packages installed will be properly loaded.\n",
        "os._exit(00)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Ie841Wt1cfJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import necessary libraries\n",
        "import tensorflow as tf\n",
        "import copy"
      ],
      "metadata": {
        "id": "FzYfeIUSInUq",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hyper-parameters\n",
        "num_labeled  = 1000\n",
        "\n",
        "# learning rates\n",
        "lr_fsp_trf   = 0.01\n",
        "lr_fsp_fnt   = 0.0001\n",
        "\n",
        "lr_prx_trf   = 0.01\n",
        "lr_prx_fnt   = 0.00001\n",
        "\n",
        "lr_dwm_trf   = 0.01\n",
        "lr_dwm_fnt   = 0.0001\n",
        "\n",
        "\n",
        "# batch sizes\n",
        "batch_fsp_trf  = 128\n",
        "batch_fsp_fnt  = 128\n",
        "\n",
        "batch_prx_trf  = 128\n",
        "batch_prx_fnt  = 128\n",
        "\n",
        "batch_dwm_trf  = 128\n",
        "batch_dwm_fnt  = 128\n",
        "\n",
        "\n",
        "# epochs\n",
        "epoch_fsp_trf  = 15\n",
        "epoch_fsp_fnt  = 10\n",
        "\n",
        "epoch_prx_trf  = 15\n",
        "epoch_prx_fnt  = 10\n",
        "\n",
        "epoch_dwm_trf  = 15\n",
        "epoch_dwm_fnt  = 10\n"
      ],
      "metadata": {
        "id": "-q5M1UgDqkDY",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load and process the CIFAR-10 data\n",
        "(datain_tr, dataou_tr), (datain_te, dataou_te) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "datain_tr = datain_tr/255 # trasnform unit-8 values between 0 and 1\n",
        "datain_te = datain_te/255 # trasnform unit-8 values between 0 and 1\n",
        "\n",
        "dataou_tr = tf.keras.utils.to_categorical(dataou_tr)\n",
        "dataou_te = tf.keras.utils.to_categorical(dataou_te)\n",
        "\n",
        "# print shapes of data\n",
        "\n",
        "print('Shape of datain_tr: {}'.format(datain_tr.shape))\n",
        "print('Shape of datain_te: {}'.format(datain_te.shape))\n",
        "print('Shape of dataou_tr: {}'.format(dataou_tr.shape))\n",
        "print('Shape of dataou_te: {}'.format(dataou_te.shape))\n"
      ],
      "metadata": {
        "id": "I15ccnhjzDMX",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create contrastive training inputs and outputs\n",
        "'''\n",
        "Let's pick an augmentation method, say, random rotation.\n",
        "'''\n",
        "\n",
        "fun_augment     = tf.keras.layers.RandomRotation(factor = 0.2)\n",
        "\n",
        "datain_tr_augmented = fun_augment(datain_tr)\n",
        "\n",
        "#concatenate the original and augmented training data for pretext (prx)\n",
        "datain_tr_prx = tf.concat([datain_tr,datain_tr_augmented], axis = 0)\n",
        "\n",
        "#contrastive outputs\n",
        "dataou_tr_prx_positive = tf.ones((datain_tr.shape[0],1))\n",
        "dataou_tr_prx_negative = tf.zeros((datain_tr_augmented.shape[0],1))\n",
        "\n",
        "#Output concatenation based on the order of data points in datain_tr_prx\n",
        "dataou_tr_prx = tf.concat([dataou_tr_prx_negative, dataou_tr_prx_positive], axis = 0)\n",
        "\n",
        "#binary categorical for SoftMax:\n",
        "dataou_tr_prx = tf.keras.utils.to_categorical(dataou_tr_prx)\n"
      ],
      "metadata": {
        "id": "zUqp7KD-vmZP",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Limit the labeled training data\n",
        "\n",
        "# randomly select num_labeled of training data\n",
        "index_tr = tf.experimental.numpy.random.randint(0, datain_tr.shape[0], num_labeled)\n",
        "\n",
        "datain_tr_labeled = datain_tr[index_tr,:,:,:]\n",
        "dataou_tr_labeled = dataou_tr[index_tr,:]\n",
        "\n",
        "datain_tr_fsp = copy.deepcopy(datain_tr_labeled)\n",
        "dataou_tr_fsp = copy.deepcopy(dataou_tr_labeled)\n",
        "\n",
        "datain_tr_dwm = copy.deepcopy(datain_tr_labeled)\n",
        "dataou_tr_dwm = copy.deepcopy(dataou_tr_labeled)\n",
        "\n",
        "# we have 50,000 training inputs; num_labeled of them are labeled\n"
      ],
      "metadata": {
        "id": "EPB_PDAPURTG",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create model_fsp and model_dwm similar to DenseNet121\n",
        "\n",
        "layerin = tf.keras.Input(shape=(datain_tr.shape[1],\n",
        "                                datain_tr.shape[2],\n",
        "                                datain_tr.shape[3]))\n",
        "\n",
        "upscale = tf.keras.layers.Lambda(lambda x: tf.image.resize_with_pad(x,\n",
        "                                                                    160,\n",
        "                                                                    160,\n",
        "                                                                    method=tf.image.ResizeMethod.BILINEAR))(layerin)\n",
        "\n",
        "# load with ImageNet Weights\n",
        "model_DenseNet121 = tf.keras.applications.DenseNet121(include_top  = False,\n",
        "                                                      weights      = \"imagenet\",\n",
        "                                                      input_shape  = (160,160,3),\n",
        "                                                      input_tensor = upscale,\n",
        "                                                      pooling      = 'max')\n",
        "\n",
        "'''\n",
        "We clone model_DenseNet121 to create model_base of our fully supervised model\n",
        "and pretext model.\n",
        "\n",
        "P.S. We clone the downstream model after the pretext task using\n",
        "the pretext model.\n",
        "'''\n",
        "\n",
        "model_base_fsp =  tf.keras.models.clone_model(model_DenseNet121)\n",
        "model_base_prx =  tf.keras.models.clone_model(model_DenseNet121)\n",
        "\n",
        "'''\n",
        "We set the parameters of model_base_fsp and model_base_prx to be the same as the\n",
        "randomly generated parameters of model_DenseNet121 to have both model learning\n",
        "start point the same for a fair comparison.\n",
        "'''\n",
        "\n",
        "model_base_fsp.set_weights(model_DenseNet121.get_weights())\n",
        "model_base_prx.set_weights(model_DenseNet121.get_weights())\n",
        "\n",
        "\n",
        "'''\n",
        "Now we create batch norm layers of model_fsp and model_prx.\n",
        "'''\n",
        "layer_batchnorm_fsp = tf.keras.layers.BatchNormalization()\n",
        "layer_batchnorm_prx = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "'''\n",
        "Now we create output layers of model_fsp and model_prx.\n",
        "'''\n",
        "layerou_fsp = tf.keras.layers.Dense(dataou_tr_fsp.shape[-1],\n",
        "                                    activation = 'softmax')\n",
        "\n",
        "layerou_prx = tf.keras.layers.Dense(dataou_tr_prx.shape[-1],\n",
        "                                    activation = 'softmax')\n",
        "\n",
        "\n",
        "'''\n",
        "Now we create model_fsp and model_prx.\n",
        "'''\n",
        "model_fsp   = tf.keras.models.Sequential([model_base_fsp,\n",
        "                                          layer_batchnorm_fsp,\n",
        "                                          layerou_fsp])\n",
        "\n",
        "model_prx   = tf.keras.models.Sequential([model_base_prx,\n",
        "                                          layer_batchnorm_prx,\n",
        "                                          layerou_prx])\n"
      ],
      "metadata": {
        "id": "1XMn2AVFy8Rg",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Train the fsp model using transfer learning and fine-tuning\n",
        "\n",
        "'''\n",
        "We don't include any validation split here since we can verify overfitting\n",
        "existence later using testing data.\n",
        "'''\n",
        "\n",
        "# transfer learning\n",
        "model_base_fsp.trainable      = False\n",
        "layer_batchnorm_fsp.trainable = False\n",
        "\n",
        "model_fsp.compile(optimizer = tf.keras.optimizers.Adam(lr_fsp_trf),\n",
        "                  loss      = 'categorical_crossentropy',\n",
        "                  metrics   = ['accuracy'])\n",
        "\n",
        "'''\n",
        "We reserve the output layer's parameters of fsp model for dwm model.\n",
        "'''\n",
        "\n",
        "layerou_fsp_initial_parameters = copy.deepcopy(model_fsp.layers[2].weights)\n",
        "\n",
        "model_fsp.summary()\n",
        "\n",
        "history_fsp_trf = model_fsp.fit(datain_tr_fsp,\n",
        "                                dataou_tr_fsp,\n",
        "                                epochs           = epoch_fsp_trf,\n",
        "                                batch_size       = batch_fsp_trf,\n",
        "                                verbose          = 1,\n",
        "                                shuffle          = True)\n",
        "\n",
        "# fine-tuning\n",
        "model_base_fsp.trainable      = True\n",
        "layer_batchnorm_fsp.trainable = True\n",
        "\n",
        "model_fsp.compile(optimizer = tf.keras.optimizers.Adam(lr_fsp_fnt),\n",
        "                  loss      = 'categorical_crossentropy',\n",
        "                  metrics   = ['accuracy'])\n",
        "\n",
        "\n",
        "model_fsp.summary()\n",
        "\n",
        "history_fsp_fnt = model_fsp.fit(datain_tr_fsp,\n",
        "                                dataou_tr_fsp,\n",
        "                                epochs           = epoch_fsp_fnt,\n",
        "                                batch_size       = batch_fsp_fnt,\n",
        "                                verbose          = 1,\n",
        "                                shuffle          = True)"
      ],
      "metadata": {
        "id": "K55ixp3vy8Rg",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Train the prx model using transfer learning and fine-tuning\n",
        "'''\n",
        "Note that we do not have testing pretext data, so we track overfitting by\n",
        "including validation split. Also, since prx takes time, we define some early\n",
        "stopping criteria using \"callbacks.\"\n",
        "'''\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor              = 'val_loss',\n",
        "                                            patience             = 1,\n",
        "                                            restore_best_weights = True)\n",
        "\n",
        "# transfer learning\n",
        "model_base_prx.trainable      = False\n",
        "layer_batchnorm_prx.trainable = False\n",
        "\n",
        "model_prx.compile(optimizer = tf.keras.optimizers.Adam(lr_prx_trf),\n",
        "                  loss      = 'categorical_crossentropy',\n",
        "                  metrics   = ['accuracy'])\n",
        "\n",
        "model_prx.summary()\n",
        "\n",
        "history_prx_trf = model_prx.fit(datain_tr_prx,\n",
        "                                dataou_tr_prx,\n",
        "                                epochs           = epoch_prx_trf,\n",
        "                                batch_size       = batch_prx_trf,\n",
        "                                verbose          = 1,\n",
        "                                shuffle          = True,\n",
        "                                validation_split = 0.05,\n",
        "                                callbacks        = [callback])\n",
        "\n",
        "# fine-tuning\n",
        "\n",
        "model_base_prx.trainable      = True\n",
        "layer_batchnorm_prx.trainable = True\n",
        "\n",
        "model_prx.compile(optimizer = tf.keras.optimizers.Adam(lr_prx_fnt),\n",
        "                  loss      = 'categorical_crossentropy',\n",
        "                  metrics   = ['accuracy'])\n",
        "\n",
        "model_prx.summary()\n",
        "\n",
        "history_prx_fnt = model_prx.fit(datain_tr_prx,\n",
        "                                dataou_tr_prx,\n",
        "                                epochs           = epoch_prx_fnt,\n",
        "                                batch_size       = batch_prx_fnt,\n",
        "                                verbose          = 1,\n",
        "                                shuffle          = True,\n",
        "                                validation_split = 0.05,\n",
        "                                callbacks        = [callback])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "cNTAM_ChlbOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create and train dwm model using transfer-learning and fine-tuning\n",
        "'''\n",
        "Downstream output layer\n",
        "'''\n",
        "layerou_dwm = tf.keras.layers.Dense(dataou_tr_dwm.shape[-1],\n",
        "                                    activation = 'softmax')\n",
        "\n",
        "'''\n",
        "Now we create model_dwm using model_base_prx (yes, it is trained!),\n",
        "layer_batchnorm_prx (yes, it is trained too!), and layerou_dwm, but for a fair\n",
        "fsp and dwm comparison, we set the dwm parameters to be similar to\n",
        "layerou_fsp_initial_parameters.\n",
        "\n",
        "P.S. Note that at the transfer learning level, we don't update model_base_prx\n",
        "and layer_batchnorm_prx  parameters and focus on learning layerou_dwm only.\n",
        "'''\n",
        "\n",
        "# Transfer learning\n",
        "model_base_prx.trainable      = False\n",
        "layer_batchnorm_prx.trainable = False\n",
        "\n",
        "model_dwm   = tf.keras.models.Sequential([model_base_prx,\n",
        "                                          layer_batchnorm_prx,\n",
        "                                          layerou_dwm])\n",
        "\n",
        "model_dwm.layers[2].set_weights(layerou_fsp_initial_parameters)\n",
        "\n",
        "model_dwm.compile(optimizer = tf.keras.optimizers.Adam(lr_dwm_trf),\n",
        "                  loss      = 'categorical_crossentropy',\n",
        "                  metrics   = ['accuracy'])\n",
        "\n",
        "model_dwm.summary()\n",
        "\n",
        "history_dwm = model_dwm.fit(datain_tr_dwm,\n",
        "                            dataou_tr_dwm,\n",
        "                            epochs           = epoch_dwm_trf,\n",
        "                            batch_size       = batch_dwm_trf,\n",
        "                            verbose          = 1,\n",
        "                            shuffle          = True)\n",
        "\n",
        "# Fine-tuning\n",
        "model_base_prx.trainable      = True\n",
        "layer_batchnorm_prx.trainable = True\n",
        "\n",
        "# We can fine-tune after certain model_base_prx layer!\n",
        "# fine_tune_after = 430\n",
        "# for layer in model_base_prx.layers[:fine_tune_after]:\n",
        "#   layer.trainable = False\n",
        "\n",
        "model_dwm.compile(optimizer = tf.keras.optimizers.Adam(lr_dwm_fnt),\n",
        "                  loss      = 'categorical_crossentropy',\n",
        "                  metrics   = ['accuracy'])\n",
        "\n",
        "model_dwm.summary()\n",
        "\n",
        "history_dwm = model_dwm.fit(datain_tr_dwm,\n",
        "                            dataou_tr_dwm,\n",
        "                            epochs           = epoch_dwm_fnt,\n",
        "                            batch_size       = batch_dwm_fnt,\n",
        "                            verbose          = 1,\n",
        "                            shuffle          = True)\n"
      ],
      "metadata": {
        "id": "za52rJgzm71v",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Compute model_fsp and model_dwm testing accuracies\n",
        "_, acc_te_fsp = model_fsp.evaluate(datain_te,\n",
        "                                   dataou_te,\n",
        "                                   batch_size = 128)\n",
        "\n",
        "_, acc_te_dwm = model_dwm.evaluate(datain_te,\n",
        "                                   dataou_te,\n",
        "                                   batch_size = 128)\n",
        "\n",
        "print('Accuracy of fsp: {:05.2f}%'.format(acc_te_fsp*100))\n",
        "print('Accuracy of dwm: {:05.2f}%'.format(acc_te_dwm*100))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "5p7gDls-y8Rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Clean up memory\n",
        "%reset"
      ],
      "metadata": {
        "cellView": "form",
        "id": "moW3GaaXy8Rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lecture 08: Supervised Contrastive Pretext, Experiment 2**\n",
        "\n",
        "In this lecture, you learned about:\n",
        "\n",
        "1. How to address a labeling problem with supervised contrastive pretext with pretrained parameters.\n",
        "\n",
        "> ***In the following lecture, we will learn about SimCLR of [Chen et al. (2020)](http://proceedings.mlr.press/v119/chen20j/chen20j.pdf), a powerful unsupervised contrastive learning technique.***"
      ],
      "metadata": {
        "id": "bBiYNuP3LRf-"
      }
    }
  ]
}