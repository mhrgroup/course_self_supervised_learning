{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mhrgroup/course_self_supervised_learning/blob/main/Section%2004%3A%20Self-Supervised%20Learning/ssl_section04_lecture10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lecture 10: SimCLR Experiment**\n",
        "\n",
        "By the end of this lecture, you will be able to:\n",
        "\n",
        "1. Address a labeling problem with SimCLR using a pretrained encoder."
      ],
      "metadata": {
        "id": "Wt9jAeTSiWju"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **10.1. Experiment**\n",
        "---\n",
        "* This experiment is similar to the previous ones too!\n",
        "* We assume only 1000 training images are labeled in CIFAR-10.\n",
        "* We develop a SimCLR pretext (prx) model using all training inputs and fine-tune it on the 1000 labeled images in the downstream (dwm) task.\n",
        "* We then label the testing images using the fine-tuned model.\n",
        "* We assume that, there is a trained encoder (regressor) on similar data distribution. Hence, our model has pretrained parameters.\n",
        "* We compare this model with the result of a fairly similar fully supervised (fsp) model trained on the 1000 labeled data.\n",
        "* Note: we have to develop three models here, model_fsp, model_prx, and model_dwm.\n",
        "\n",
        "> **Abbreviations:**\n",
        "* acc: accuracy\n",
        "*\tdatain: input data\n",
        "*\tdataou: output data\n",
        "*\tdwm: downstream\n",
        "*\tfnt: fine-tuning\n",
        "*\tfsp: fully supervised learning\n",
        "* ind:index\n",
        "* lr: learning rate\n",
        "*\tprx: pretext\n",
        "*\tte: testing\n",
        "*\ttf: tensorflow\n",
        "*\ttr: training\n",
        "*\ttrf: transfer learning"
      ],
      "metadata": {
        "id": "SFe73rDdh8yt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import necessary libraries\n",
        "import tensorflow as tf\n",
        "import copy\n",
        "import warnings\n",
        "\n",
        "from IPython.display import clear_output\n",
        "# tqdm provides a simple and convenient way to add progress bars to loops.\n",
        "from tqdm import tqdm\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "FzYfeIUSInUq",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hyper-parameters\n",
        "num_labeled  = 1000\n",
        "\n",
        "# learning rates\n",
        "lr_fsp_trf   = 0.01\n",
        "lr_fsp_fnt   = 0.0001\n",
        "\n",
        "lr_prx_trf   = 0.01\n",
        "lr_prx_fnt   = 0.000001\n",
        "\n",
        "lr_dwm_trf   = 0.01\n",
        "lr_dwm_fnt   = 0.0001\n",
        "\n",
        "\n",
        "# batch sizes\n",
        "batch_fsp_trf  = 64\n",
        "batch_fsp_fnt  = 64\n",
        "\n",
        "batch_prx_trf  = 32\n",
        "batch_prx_fnt  = 32\n",
        "\n",
        "batch_dwm_trf  = 64\n",
        "batch_dwm_fnt  = 64\n",
        "\n",
        "\n",
        "# epochs\n",
        "epoch_fsp_trf  = 15\n",
        "epoch_fsp_fnt  = 10\n",
        "\n",
        "epoch_prx_trf  = 15\n",
        "epoch_prx_fnt  = 10\n",
        "\n",
        "epoch_dwm_trf  = 15\n",
        "epoch_dwm_fnt  = 10\n"
      ],
      "metadata": {
        "id": "-q5M1UgDqkDY",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load and process the CIFAR-10 data\n",
        "(datain_tr, dataou_tr), (datain_te, dataou_te) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "datain_tr = datain_tr/255 # trasnform unit-8 values between 0 and 1\n",
        "datain_te = datain_te/255 # trasnform unit-8 values between 0 and 1\n",
        "\n",
        "dataou_tr = tf.keras.utils.to_categorical(dataou_tr)\n",
        "dataou_te = tf.keras.utils.to_categorical(dataou_te)\n",
        "\n",
        "print('Shape of datain_tr: {}'.format(datain_tr.shape))\n",
        "print('Shape of datain_te: {}'.format(datain_te.shape))\n",
        "print('Shape of dataou_tr: {}'.format(dataou_tr.shape))\n",
        "print('Shape of dataou_te: {}'.format(dataou_te.shape))\n"
      ],
      "metadata": {
        "id": "I15ccnhjzDMX",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Pick two augmentation functions\n",
        "\n",
        "# Crop and Resize\n",
        "fun_augment_a  = tf.keras.layers.RandomCrop(height = 20, width = 20)\n",
        "fun_augment_b  = tf.keras.layers.Resizing(height = datain_tr.shape[1],\n",
        "                                          width = datain_tr.shape[2])\n",
        "\n",
        "fun_augment_01 = tf.keras.Sequential([fun_augment_a, fun_augment_b])\n",
        "\n",
        "# Random rotation\n",
        "fun_augment_02     = tf.keras.layers.RandomRotation(factor = 0.2)"
      ],
      "metadata": {
        "id": "zUqp7KD-vmZP",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Limit the labeled training data\n",
        "\n",
        "# Randomly select num_labeled of training data\n",
        "index_tr = tf.experimental.numpy.random.randint(0,\n",
        "                                                datain_tr.shape[0],\n",
        "                                                num_labeled)\n",
        "\n",
        "datain_tr_labeled = datain_tr[index_tr,:,:,:]\n",
        "dataou_tr_labeled = dataou_tr[index_tr,:]\n",
        "\n",
        "datain_tr_fsp = copy.deepcopy(datain_tr_labeled)\n",
        "dataou_tr_fsp = copy.deepcopy(dataou_tr_labeled)\n",
        "\n",
        "datain_tr_prx = copy.deepcopy(datain_tr)\n",
        "\n",
        "datain_tr_dwm = copy.deepcopy(datain_tr_labeled)\n",
        "dataou_tr_dwm = copy.deepcopy(dataou_tr_labeled)\n",
        "\n",
        "# We have 50,000 training inputs; num_labeled of them are labeled\n"
      ],
      "metadata": {
        "id": "EPB_PDAPURTG",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Custom loss function\n",
        "# Updated on 20240506 for TensorFlow 2.15.0\n",
        "@tf.function\n",
        "def fun_simclr_loss(z_real, z_estimate):\n",
        "    # The z_real parameter is not used since SimCLR is an unsupervised model.\n",
        "    # This dummy variable is discarded.\n",
        "    del z_real\n",
        "\n",
        "    # Temperature parameter is set to 0.1. This hyperparameter can be tuned\n",
        "    # for specific problems to control the smoothness of the output distribution.\n",
        "    toe = .1\n",
        "\n",
        "    # Calculate the number of projections, which is twice the batch size (2N).\n",
        "    num = z_estimate.shape[0]\n",
        "\n",
        "    # Generate two sets of indices for all possible pair combinations within the batch.\n",
        "    # ind0 is a temporary variable holding the repeated range for generating indices.\n",
        "    ind0 = tf.repeat(tf.expand_dims(tf.range(0, num), axis=0), num, axis=0)\n",
        "    # Flatten ind0 to create a single list of indices for the first element of pairs.\n",
        "    ind1 = tf.reshape(ind0, (num**2, 1))[:, 0]\n",
        "    # Flatten the transpose of ind0 to create a single list of indices for the second element of pairs.\n",
        "    ind2 = tf.reshape(tf.transpose(ind0), (num**2, 1))[:, 0]\n",
        "\n",
        "    # The temporary index tensor is no longer needed after use.\n",
        "    del ind0\n",
        "\n",
        "    # Select the projections based on the first set of indices to form the first elements of pairs.\n",
        "    vector_1 = tf.gather(z_estimate, ind1, axis=0)\n",
        "    # The first set of indices is no longer needed after use.\n",
        "    del ind1\n",
        "\n",
        "    # Select the projections based on the second set of indices to form the second elements of pairs.\n",
        "    vector_2 = tf.gather(z_estimate, ind2, axis=0)\n",
        "    # The second set of indices is no longer needed after use.\n",
        "    del ind2\n",
        "\n",
        "    # Calculate the cosine similarity between each pair of projections and negate it to prepare for loss calculation.\n",
        "    s = -tf.reshape(tf.keras.losses.cosine_similarity(vector_1, vector_2, axis=1), (num, num))\n",
        "\n",
        "    # The vector tensors are no longer needed after computing similarities.\n",
        "    del vector_1\n",
        "    del vector_2\n",
        "\n",
        "    # Calculate the nominator of the contrastive loss function for each pair.\n",
        "    nom = tf.exp(s / toe)\n",
        "\n",
        "    # Calculate the denominator of the contrastive loss function by excluding the self-similarity term.\n",
        "    x1 = tf.exp(s / toe)\n",
        "    x2 = 1 - tf.eye(num, dtype=tf.float32)\n",
        "    denom = tf.repeat(tf.expand_dims(tf.math.reduce_sum(x1 * x2, axis=1), axis=1), num, axis=1)\n",
        "\n",
        "    # The intermediate tensors used for the denominator are no longer needed.\n",
        "    del s\n",
        "    del x1\n",
        "    del x2\n",
        "\n",
        "    # Calculate the loss `l(i, j)` for each pair of projections using the computed nominator and denominator.\n",
        "    l = -tf.math.log(nom / denom)\n",
        "\n",
        "    # Cleanup intermediate tensors to save memory.\n",
        "    del nom\n",
        "    del denom\n",
        "\n",
        "    # Prepare indices to extract the diagonal elements from the loss matrix, which correspond to the actual pair losses.\n",
        "    ind_2k0 = tf.range(0, num, 2, dtype=tf.int32)  # Even indices\n",
        "    ind_2k1 = tf.range(1, num, 2, dtype=tf.int32)  # Odd indices\n",
        "\n",
        "    # Extract and sum the losses for the actual pairs using the prepared indices.\n",
        "    loss_mat1_1 = tf.gather(l, ind_2k0, axis=0)\n",
        "    loss_mat1_2 = tf.gather(loss_mat1_1, ind_2k1, axis=1)\n",
        "    loss_mat1 = tf.linalg.diag_part(loss_mat1_2)\n",
        "\n",
        "    loss_mat2_1 = tf.gather(l, ind_2k1, axis=0)\n",
        "    loss_mat2_2 = tf.gather(loss_mat2_1, ind_2k0, axis=1)\n",
        "    loss_mat2 = tf.linalg.diag_part(loss_mat2_2)\n",
        "\n",
        "    # After extracting the necessary elements, the large loss tensor can be discarded.\n",
        "    del l\n",
        "\n",
        "    # Combine the individual loss components into a single tensor.\n",
        "    loss_mat = loss_mat1 + loss_mat2\n",
        "\n",
        "    # Compute the final loss by taking the sum over all individual losses and normalizing by the number of pairs.\n",
        "    L = tf.math.reduce_sum(loss_mat) / num\n",
        "\n",
        "\n",
        "    # Return the final computed loss.\n",
        "    return L"
      ],
      "metadata": {
        "id": "zIKranjD3JY4",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title SimCLR training function\n",
        "# Updated on 20240506 for TensorFlow 2.15.0\n",
        "# At the records of the videos, we had TensorFlow version 2.9.0.\n",
        "# The latest version of TensorFlow is 2.15.0 as of 20240506. As such, we updated\n",
        "# our code significantly to increase its efficiency and make it aligned with\n",
        "# TesnorFlow version 2.15.0. The code is commented on so that students can\n",
        "# study the updates.\n",
        "\n",
        "def fun_train_simclr(model, images, fun_augment_01, fun_augment_02,\n",
        "                     epochs=100, batch_size = 16, verbose=1, patience=3, learning_rate=0.001):\n",
        "\n",
        "    # Determine the output size of the model's last layer\n",
        "    z_size = model.layers[-1].weights[-1].shape[0]\n",
        "\n",
        "    # Initialize a list to keep track of the loss values for each epoch\n",
        "    loss = []\n",
        "\n",
        "    # Initialize the optimizer with the specified learning rate\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    # Create a TensorFlow Dataset\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(images)\n",
        "    dataset = dataset.shuffle(buffer_size=10000)  # Adjust buffer size to your dataset size/available memory\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.cache()  # Cache the data to avoid re-reading from disk/memory each epoch\n",
        "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)  # Prefetch batches in the background\n",
        "\n",
        "    # Loop through each epoch\n",
        "    for epoch in range(epochs):\n",
        "        # Initialize a variable to keep track of the running loss for the current epoch\n",
        "        loss_running = 0\n",
        "\n",
        "        # Initialize a progress bar using tqdm to visualize training progress\n",
        "        pbar = tqdm(dataset,\n",
        "                    desc  = f\"SimCLR Training: {epoch + 1:03d}/{epochs}\", # Description shown in the progress bar\n",
        "                    ncols = 125, # Width of the progress bar\n",
        "                    leave = True) # Whether the progress bar should remain after completion\n",
        "\n",
        "        # Iterate over each batch in the dataset\n",
        "        for batch_num, batch in enumerate(pbar, 1):\n",
        "            if isinstance(batch, tuple):\n",
        "                batch_in = batch[0] # Get the input data from the batch\n",
        "            else:\n",
        "                batch_in = batch\n",
        "\n",
        "            # Apply two different augmentations to the input data\n",
        "            x_tilda_01 = fun_augment_01(batch_in)\n",
        "            x_tilda_02 = fun_augment_02(batch_in)\n",
        "\n",
        "            # Concatenate the augmented data along the batch axis and reshape it for the model input\n",
        "            x_tilda = tf.reshape(tf.concat([x_tilda_01, x_tilda_02], axis=0),\n",
        "                                (x_tilda_01.shape[0] * 2, # Corrected to ensure the correct shape for concatenation\n",
        "                                 x_tilda_01.shape[1], x_tilda_01.shape[2],\n",
        "                                 x_tilda_01.shape[3]))\n",
        "\n",
        "            # Create a dummy output tensor of the same size as the model's output\n",
        "            z_real = tf.random.uniform((x_tilda.shape[0], z_size))\n",
        "\n",
        "            # Open a GradientTape to record the operations for automatic differentiation\n",
        "            with tf.GradientTape() as tape:\n",
        "                # Pass the concatenated and augmented inputs through the model\n",
        "                z_estimate = model(x_tilda, training=True)\n",
        "\n",
        "                # Calculate the batch loss using the custom SimCLR loss function\n",
        "                loss_batch = fun_simclr_loss(z_real, z_estimate)\n",
        "\n",
        "            # Calculate the gradients of the loss with respect to the model's trainable variables\n",
        "            gradients = tape.gradient(loss_batch, model.trainable_variables)\n",
        "\n",
        "            # Apply the calculated gradients to the model's variables to minimize the loss\n",
        "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "            # Update the running loss for the epoch\n",
        "            loss_running += loss_batch.numpy()  # Ensure loss is a scalar by calling .numpy()\n",
        "\n",
        "            # If verbose, update the progress bar with the current average loss\n",
        "            if verbose:\n",
        "                pbar.set_postfix(loss = f\"{loss_running/batch_num:.6f}\")\n",
        "\n",
        "        # Append the average loss for this epoch to the loss history\n",
        "        loss.append(loss_running / batch_num)\n",
        "\n",
        "        # Check for early stopping: if there's no improvement in loss for a specified number of epochs, stop training\n",
        "        if epoch >= patience:\n",
        "            if loss[-1] > min(loss[:-patience]):\n",
        "                print(\"Early stopping due to no improvement in loss.\")\n",
        "                break  # Exit the training loop\n",
        "\n",
        "    # Return the trained model and the history of loss values\n",
        "    return model, loss"
      ],
      "metadata": {
        "id": "FFiElm3x3JRW",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create model_fsp and model_dwm similar to DenseNet121\n",
        "\n",
        "layerin = tf.keras.Input(shape=(datain_tr.shape[1],\n",
        "                                datain_tr.shape[2],\n",
        "                                datain_tr.shape[3]))\n",
        "\n",
        "upscale = tf.keras.layers.Lambda(lambda x: tf.image.resize_with_pad(x,\n",
        "                                                                    160,\n",
        "                                                                    160,\n",
        "                                                                    method=tf.image.ResizeMethod.BILINEAR))(layerin)\n",
        "\n",
        "model_DenseNet121 = tf.keras.applications.DenseNet121(include_top  = False,\n",
        "                                                      weights      = \"imagenet\",\n",
        "                                                      input_shape  = (160,160,3),\n",
        "                                                      input_tensor = upscale,\n",
        "                                                      pooling      = 'max')\n",
        "\n",
        "model_base_fsp =  tf.keras.models.clone_model(model_DenseNet121)\n",
        "model_base_prx =  tf.keras.models.clone_model(model_DenseNet121) # encoder\n",
        "\n",
        "model_base_fsp.set_weights(model_DenseNet121.get_weights())\n",
        "model_base_prx.set_weights(model_DenseNet121.get_weights())\n",
        "\n",
        "\n",
        "layer_batchnorm_fsp = tf.keras.layers.BatchNormalization()\n",
        "layer_batchnorm_prx = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "'''\n",
        "Now we create the SimCLR projector.\n",
        "'''\n",
        "\n",
        "layers_dense_prx = [tf.keras.Input(shape=(1024)),\n",
        "                    tf.keras.layers.Dense(512, activation = 'relu'),\n",
        "                    tf.keras.layers.Dense(128, activation = 'relu')]\n",
        "\n",
        "model_projector = tf.keras.Sequential(layers_dense_prx)\n",
        "\n",
        "'''\n",
        "Now we create output layers of model_fsp.\n",
        "'''\n",
        "\n",
        "layerou_fsp = tf.keras.layers.Dense(dataou_tr_fsp.shape[-1], activation = 'softmax')\n",
        "#layerou_prx = tf.keras.layers.Dense(dataou_tr_prx.shape[-1], activation = 'softmax')\n",
        "\n",
        "\n",
        "'''\n",
        "Now we create model_fsp and model_prx.\n",
        "'''\n",
        "\n",
        "model_fsp   = tf.keras.models.Sequential([model_base_fsp,\n",
        "                                          layer_batchnorm_fsp,\n",
        "                                          layerou_fsp])\n",
        "\n",
        "model_prx   = tf.keras.models.Sequential([model_base_prx,\n",
        "                                          layer_batchnorm_prx,\n",
        "                                          model_projector])\n"
      ],
      "metadata": {
        "id": "1XMn2AVFy8Rg",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Train the fsp model using transfer learning and fine-tuning\n",
        "\n",
        "# Transfer learning\n",
        "model_base_fsp.trainable      = False\n",
        "layer_batchnorm_fsp.trainable = False\n",
        "\n",
        "model_fsp.compile(optimizer = tf.keras.optimizers.Adam(lr_fsp_trf),\n",
        "                  loss      = 'categorical_crossentropy',\n",
        "                  metrics   = ['accuracy'])\n",
        "\n",
        "layerou_fsp_initial_parameters = copy.deepcopy(model_fsp.layers[2].weights)\n",
        "\n",
        "model_fsp.summary()\n",
        "\n",
        "history_fsp_trf = model_fsp.fit(datain_tr_fsp,\n",
        "                                dataou_tr_fsp,\n",
        "                                epochs           = epoch_fsp_trf,\n",
        "                                batch_size       = batch_fsp_trf,\n",
        "                                verbose          = 1,\n",
        "                                shuffle          = True)\n",
        "\n",
        "# Fine-tuning\n",
        "\n",
        "model_base_fsp.trainable      = True\n",
        "layer_batchnorm_fsp.trainable = True\n",
        "\n",
        "model_fsp.compile(optimizer = tf.keras.optimizers.Adam(lr_fsp_fnt),\n",
        "                  loss      = 'categorical_crossentropy',\n",
        "                  metrics   = ['accuracy'])\n",
        "\n",
        "\n",
        "model_fsp.summary()\n",
        "\n",
        "history_fsp_fnt = model_fsp.fit(datain_tr_fsp,\n",
        "                                dataou_tr_fsp,\n",
        "                                epochs           = epoch_fsp_fnt,\n",
        "                                batch_size       = batch_fsp_fnt,\n",
        "                                verbose          = 1,\n",
        "                                shuffle          = True)"
      ],
      "metadata": {
        "id": "K55ixp3vy8Rg",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Train the prx model using transfer learning and fine-tuning\n",
        "# Updated on 20240506\n",
        "# Transfer learning\n",
        "model_base_prx.trainable      = False\n",
        "layer_batchnorm_prx.trainable = False\n",
        "\n",
        "model_prx.compile(optimizer = tf.keras.optimizers.Adam(lr_prx_trf),\n",
        "                  loss      = fun_simclr_loss,\n",
        "                  metrics   = 'mean_squared_error')\n",
        "\n",
        "model_prx.summary()\n",
        "\n",
        "model_prx, _ = fun_train_simclr(model_prx,\n",
        "                                datain_tr_prx,\n",
        "                                fun_augment_01,\n",
        "                                fun_augment_02,\n",
        "                                epochs     = epoch_prx_trf,\n",
        "                                batch_size = batch_prx_trf,\n",
        "                                verbose    = 1,\n",
        "                                patience   = 1,\n",
        "                                learning_rate = lr_prx_trf)\n",
        "\n",
        "\n",
        "# Fine-tuning\n",
        "\n",
        "model_base_prx.trainable      = True\n",
        "layer_batchnorm_prx.trainable = True\n",
        "\n",
        "model_prx.compile(optimizer = tf.keras.optimizers.Adam(lr_prx_fnt),\n",
        "                  loss      = fun_simclr_loss,\n",
        "                  metrics   = 'mean_squared_error')\n",
        "\n",
        "model_prx.summary()\n",
        "\n",
        "model_prx, _ = fun_train_simclr(model_prx,\n",
        "                                datain_tr_prx,\n",
        "                                fun_augment_01,\n",
        "                                fun_augment_02,\n",
        "                                epochs     = epoch_prx_fnt,\n",
        "                                batch_size = batch_prx_fnt,\n",
        "                                verbose    = 1,\n",
        "                                patience   = 1,\n",
        "                                learning_rate = lr_prx_fnt)\n"
      ],
      "metadata": {
        "id": "cNTAM_ChlbOH",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create and train dwm model using transfer-learning and fine-tuning\n",
        "\n",
        "layerou_dwm = tf.keras.layers.Dense(dataou_tr_dwm.shape[-1],\n",
        "                                    activation = 'softmax')\n",
        "\n",
        "model_base_prx.trainable      = False\n",
        "layer_batchnorm_prx.trainable = False\n",
        "\n",
        "model_dwm   = tf.keras.models.Sequential([model_base_prx,\n",
        "                                          layer_batchnorm_prx,\n",
        "                                          layerou_dwm])\n",
        "\n",
        "model_dwm.layers[2].set_weights(layerou_fsp_initial_parameters)\n",
        "\n",
        "# Transfer learning\n",
        "model_dwm.compile(optimizer = tf.keras.optimizers.Adam(lr_dwm_trf),\n",
        "                  loss      = 'categorical_crossentropy',\n",
        "                  metrics   = ['accuracy'])\n",
        "\n",
        "model_dwm.summary()\n",
        "\n",
        "history_dwm = model_dwm.fit(datain_tr_dwm,\n",
        "                            dataou_tr_dwm,\n",
        "                            epochs           = epoch_dwm_trf,\n",
        "                            batch_size       = batch_dwm_trf,\n",
        "                            verbose          = 1,\n",
        "                            shuffle          = True)\n",
        "\n",
        "#Fine-tuning\n",
        "model_base_prx.trainable      = True\n",
        "layer_batchnorm_prx.trainable = True\n",
        "\n",
        "# We can fine-tune after certain model_base_prx layer!\n",
        "# fine_tune_after = 430\n",
        "# for layer in model_base_prx.layers[:fine_tune_after]:\n",
        "#   layer.trainable = False\n",
        "\n",
        "model_dwm.compile(optimizer = tf.keras.optimizers.Adam(lr_dwm_fnt),\n",
        "                  loss      = 'categorical_crossentropy',\n",
        "                  metrics   = ['accuracy'])\n",
        "\n",
        "model_dwm.summary()\n",
        "\n",
        "history_dwm = model_dwm.fit(datain_tr_dwm,\n",
        "                            dataou_tr_dwm,\n",
        "                            epochs           = epoch_dwm_fnt,\n",
        "                            batch_size       = batch_dwm_fnt,\n",
        "                            verbose          = 1,\n",
        "                            shuffle          = True)\n"
      ],
      "metadata": {
        "id": "za52rJgzm71v",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Compute model_fsp and model_dwm testing accuracies\n",
        "_, acc_te_fsp = model_fsp.evaluate(datain_te,\n",
        "                                   dataou_te,\n",
        "                                   batch_size = 128)\n",
        "\n",
        "_, acc_te_dwm = model_dwm.evaluate(datain_te,\n",
        "                                   dataou_te,\n",
        "                                   batch_size = 128)\n",
        "\n",
        "print('Accuracy of fsp: {:05.2f}%'.format(acc_te_fsp*100))\n",
        "print('Accuracy of dwm: {:05.2f}%'.format(acc_te_dwm*100))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "5p7gDls-y8Rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Clean up memory\n",
        "%reset"
      ],
      "metadata": {
        "cellView": "form",
        "id": "moW3GaaXy8Rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lecture 10: SimCLR, An Unsupervised Contrastive Pretext, Experiment**\n",
        "\n",
        "\n",
        "In this lecture, you learned about:\n",
        "\n",
        "1. A labeling problem with SimCLR using a pretrained encoder.\n",
        "\n",
        "\n",
        "> ***Congratulations on completing this course!***\n",
        "\n",
        "> * I hope this helps you learn SSL and how to apply it for labeling tasks.\n",
        "* You can use the same idea in data domains other than the image domain, such as temporal records and natural language processing.\n",
        "* $\\color{red}{\\text{Please rate this course and write a review.}}$\n",
        "\n",
        "Stay safe and sound!\n",
        "\n",
        "Mohammad H. Rafiei, Ph.D.\n",
        "\n",
        "* https://ep.jhu.edu/faculty/mohammad-rafiei/\n",
        "* https://scholar.google.com/citations?user=74pUQ3sAAAAJ&hl=en\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bBiYNuP3LRf-"
      }
    }
  ]
}