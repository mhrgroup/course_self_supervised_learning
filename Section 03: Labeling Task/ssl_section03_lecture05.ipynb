{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ssl_section03_lecture05.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mhrgroup/course_self_supervised_learning/blob/main/Section%2003%3A%20Labeling%20Task/ssl_section03_lecture05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lecture 05: Labeling Challenges**\n",
        "\n",
        "By the end of this lecture, you will be able to:\n",
        "\n",
        "1. Describe the challenges of labeling large repositories.\n",
        "2. Implement supervised labeling.\n"
      ],
      "metadata": {
        "id": "Wt9jAeTSiWju"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5.1. Labeling Large Repositories**\n",
        "\n",
        "---\n",
        "\n",
        "**Solution 1:** Manual labeling, for example:\n",
        "\n",
        "* Manually label a repository of ten million animal images.\n",
        "\n",
        "* Identify positive, negative, and neutral statements in thousands of text documents.\n",
        "\n",
        "* Characterize materials properties by purchasing ingredients and laboratory equipment and hiring experts to build and break thousands of materials sample.\n",
        "\n",
        "> ***Manual labeling is often a costly, labor-intensive, and time-consuming task.***\n",
        "\n",
        "**Solution 2:** Manually label a small portion of the data first. Next, develop a supervised learning model to learn from the labeled data as the training and label the rest.\n",
        "\n",
        "* Letâ€™s say we have ten million images of cats and dogs, with only 10,000 (0.1%) of them manually labeled. The problem is how to label the unlabeled images (i.e., 9,990,000 images)?\n",
        "\n",
        "* Since the training rate is only 0.1% (i.e., testing rate of 99.9%), the model is highly probable to be inaccurate and/or overfitted.\n",
        "\n",
        "* We can benefit from transfer learning and fine-tuning techniques to increase the accuracy of such supervised models.\n",
        "\n",
        "> ***Heads up: it should be noted that in either of these solutions, the unlabeled portion of the repository is unused.***\n",
        "\n",
        "* Let's create experiments to practice supervised labeling using CIFAR-10.\n",
        "\n",
        "> **Abbreviations:**\n",
        "*\tdatain: input data\n",
        "*\tdataou: output data\n",
        "*\tte: testing\n",
        "*\ttf: tensorflow\n",
        "*\ttr: training"
      ],
      "metadata": {
        "id": "_HZpivcT8qQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install necessary libraries & restart the session\n",
        "\n",
        "# Install the required libraries using the `pip` package manager.\n",
        "!pip install tensorflow==2.15\n",
        "\n",
        "# Import the time module to add a delay before restarting the session.\n",
        "import time\n",
        "\n",
        "# Import `clear_output` from IPython to clear the notebook output, ensuring a clean display for the user.\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Clear the output after the packages are installed to make the notebook cleaner.\n",
        "clear_output()\n",
        "\n",
        "# Print a message to let the user know that the libraries are installed & the session will restart.\n",
        "print(\"Necessary Libraries are Installed. Restarting the session!\")\n",
        "\n",
        "# Add a short delay (1 second) before restarting to allow the message to be displayed to the user.\n",
        "time.sleep(1)\n",
        "\n",
        "# Import the `os` module to access low-level operating system functionality.\n",
        "import os\n",
        "\n",
        "# Use `os._exit(00)` to exit the current Python runtime environment forcefully.\n",
        "# This effectively simulates a restart in notebook environments like Google Colab or Jupyter.\n",
        "# After this command, the environment will be restarted & all the packages installed will be properly loaded.\n",
        "os._exit(00)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ma_AoxFHd8fS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5.2. Supervised Labeling Experiments with Limited Labeled Data**\n",
        "---"
      ],
      "metadata": {
        "id": "n2IyKU1JJLWy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2.1. Supervised Labeling with Randomly Generated Parameters"
      ],
      "metadata": {
        "id": "SxXux91EJiJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import necessary libraries\n",
        "import time\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "Pi1aPv0z4M6V",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load and process the CIFAR-10 data\n",
        "(datain_tr, dataou_tr), (datain_te, dataou_te) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "datain_tr = datain_tr/255 # trasnform unit-8 values between 0 and 1\n",
        "datain_te = datain_te/255 # trasnform unit-8 values between 0 and 1\n",
        "\n",
        "dataou_tr = tf.keras.utils.to_categorical(dataou_tr)\n",
        "dataou_te = tf.keras.utils.to_categorical(dataou_te)\n",
        "\n",
        "print('Shape of datain_tr: {}'.format(datain_tr.shape))\n",
        "print('Shape of datain_te: {}'.format(datain_te.shape))\n",
        "print('Shape of dataou_tr: {}'.format(dataou_tr.shape))\n",
        "print('Shape of dataou_te: {}'.format(dataou_te.shape))\n"
      ],
      "metadata": {
        "id": "ElO3hBIj5WN1",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Limit the labeled training data\n",
        "'''\n",
        "Let's say we use 5% of training inputs and outputs.\n",
        "'''\n",
        "\n",
        "rate_labeled = 0.05\n",
        "num_labeled  = int(datain_tr.shape[0] * rate_labeled)\n",
        "\n",
        "print(\"Number of labeled training data: {}\".format(num_labeled))\n",
        "\n",
        "# randomly select 5% of training data\n",
        "index_tr  = tf.experimental.numpy.random.randint(0,\n",
        "                                                 datain_tr.shape[0],\n",
        "                                                 num_labeled)\n",
        "\n",
        "datain_tr = datain_tr[index_tr,:,:,:]\n",
        "dataou_tr = dataou_tr[index_tr,:]\n",
        "\n",
        "# print shapes of data\n",
        "\n",
        "print('Shape of datain_tr: {}'.format(datain_tr.shape))\n",
        "print('Shape of datain_te: {}'.format(datain_te.shape))\n",
        "print('Shape of dataou_tr: {}'.format(dataou_tr.shape))\n",
        "print('Shape of dataou_te: {}'.format(dataou_te.shape))\n"
      ],
      "metadata": {
        "id": "EPB_PDAPURTG",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create a model similar to DenseNet121\n",
        "\n",
        "layerin = tf.keras.Input(shape=(datain_tr.shape[1],\n",
        "                                datain_tr.shape[2],\n",
        "                                datain_tr.shape[3]))\n",
        "\n",
        "upscale = tf.keras.layers.Lambda(lambda x: tf.image.resize_with_pad(x,\n",
        "                                                                    160,\n",
        "                                                                    160,\n",
        "                                                                    method=tf.image.ResizeMethod.BILINEAR))(layerin)\n",
        "\n",
        "model_DenseNet121 = tf.keras.applications.DenseNet121(include_top  = False,\n",
        "                                                      weights      = None,\n",
        "                                                      input_shape  = (160,160,3),\n",
        "                                                      input_tensor = upscale,\n",
        "                                                      pooling      = 'max')\n",
        "\n",
        "layerou = tf.keras.layers.Dense(dataou_tr.shape[-1], activation = 'softmax')\n",
        "\n",
        "model   = tf.keras.models.Sequential([model_DenseNet121,\n",
        "                                      tf.keras.layers.BatchNormalization(),\n",
        "                                      layerou])\n",
        "\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(0.001),\n",
        "              loss      = 'categorical_crossentropy',\n",
        "              metrics   = ['accuracy'])\n",
        "\n",
        "print('\\nsummary of model_DenseNet121:\\n')\n",
        "model_DenseNet121.summary()\n",
        "\n",
        "print('\\nsummary of model:\\n')\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "LwUa5arM7laX",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Train the model for five epochs\n",
        "t_start = time.time()\n",
        "\n",
        "history = model.fit(datain_tr,\n",
        "                    dataou_tr,\n",
        "                    epochs           = 5,\n",
        "                    batch_size       = 128,\n",
        "                    verbose          = 1,\n",
        "                    shuffle          = True,\n",
        "                    validation_split = 0.05)\n",
        "\n",
        "t_end   = time.time()\n"
      ],
      "metadata": {
        "id": "cs1E9rVQJf0A",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Compute testing accuracy\n",
        "_, accuracy_te = model.evaluate(datain_te,\n",
        "                                dataou_te,\n",
        "                                batch_size = 128)\n",
        "\n",
        "print('\\nTraining time: {:06.2f} sec'.format(t_end - t_start))\n",
        "print('\\nTesting acuuracy: {:05.2f}%'.format(accuracy_te * 100))"
      ],
      "metadata": {
        "id": "Z7P-IZ43LNVw",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Clean up memory\n",
        "%reset"
      ],
      "metadata": {
        "id": "mW2CJLKnWPFX",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2.2. Supervised Labeling with Transfer Learning and Fine-Tuning"
      ],
      "metadata": {
        "id": "EKw18EB5JntG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import necessary libraries\n",
        "import time\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "pI9Y_6LGYbgb",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load and process the CIFAR-10 data\n",
        "(datain_tr, dataou_tr), (datain_te, dataou_te) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "datain_tr = datain_tr/255 # trasnform unit-8 values between 0 and 1\n",
        "datain_te = datain_te/255 # trasnform unit-8 values between 0 and 1\n",
        "\n",
        "dataou_tr = tf.keras.utils.to_categorical(dataou_tr)\n",
        "dataou_te = tf.keras.utils.to_categorical(dataou_te)\n",
        "\n",
        "# print shapes of data\n",
        "\n",
        "print('Shape of datain_tr: {}'.format(datain_tr.shape))\n",
        "print('Shape of datain_te: {}'.format(datain_te.shape))\n",
        "print('Shape of dataou_tr: {}'.format(dataou_tr.shape))\n",
        "print('Shape of dataou_te: {}'.format(dataou_te.shape))\n"
      ],
      "metadata": {
        "id": "sCPz7gCaWJJx",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Limit the labeled training data\n",
        "'''\n",
        "Let's say we use 5% of training inputs and outputs.\n",
        "'''\n",
        "rate_labeled = 0.05\n",
        "num_labeled  = int(datain_tr.shape[0] * rate_labeled)\n",
        "\n",
        "print(\"Number of labeled training data: {}\".format(num_labeled))\n",
        "\n",
        "# randomly select 5% of training data\n",
        "index_tr  = tf.experimental.numpy.random.randint(0,\n",
        "                                                 datain_tr.shape[0],\n",
        "                                                 num_labeled)\n",
        "\n",
        "datain_tr = datain_tr[index_tr,:,:,:]\n",
        "dataou_tr = dataou_tr[index_tr,:]\n",
        "\n",
        "# print shapes of data\n",
        "\n",
        "print('Shape of datain_tr: {}'.format(datain_tr.shape))\n",
        "print('Shape of datain_te: {}'.format(datain_te.shape))\n",
        "print('Shape of dataou_tr: {}'.format(dataou_tr.shape))\n",
        "print('Shape of dataou_te: {}'.format(dataou_te.shape))"
      ],
      "metadata": {
        "id": "1yFZgpmIBuYX",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create a model similar to DenseNet121\n",
        "layerin = tf.keras.Input(shape=(datain_tr.shape[1], datain_tr.shape[2],datain_tr.shape[3]))\n",
        "\n",
        "upscale = tf.keras.layers.Lambda(lambda x: tf.image.resize_with_pad(x,\n",
        "                                                                    160,\n",
        "                                                                    160,\n",
        "                                                                    method=tf.image.ResizeMethod.BILINEAR))(layerin)\n",
        "\n",
        "'''\n",
        "Here we are going to use ImageNet weights to create our base model.\n",
        "'''\n",
        "model_base = tf.keras.applications.DenseNet121(include_top  = False,\n",
        "                                               weights      = 'imagenet',\n",
        "                                               input_shape  = (160,160,3),\n",
        "                                               input_tensor = upscale,\n",
        "                                               pooling      = 'max')\n",
        "\n",
        "layerou = tf.keras.layers.Dense(dataou_tr.shape[-1], activation = 'softmax')\n",
        "\n",
        "model   = tf.keras.models.Sequential([model_base,\n",
        "                                      tf.keras.layers.BatchNormalization(),\n",
        "                                      layerou])\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(0.001),\n",
        "              loss      = 'categorical_crossentropy',\n",
        "              metrics   = ['accuracy'])\n",
        "\n",
        "print('\\nsummary of model_DenseNet121:\\n')\n",
        "model_base.summary()\n",
        "\n",
        "print('\\nsummary of model:\\n')\n",
        "model.summary()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xp0spTuOWJJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Transfer learning\n",
        "'''\n",
        "Freeze the base model and train the last layer only.\n",
        "'''\n",
        "model_base.trainable = False\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(0.001),\n",
        "              loss      = 'categorical_crossentropy',\n",
        "              metrics   = ['accuracy'])\n",
        "\n",
        "print('\\nsummary of model_DenseNet121:\\n')\n",
        "model_base.summary()\n",
        "\n",
        "print('\\nsummary of model:\\n')\n",
        "model.summary()\n",
        "\n",
        "'''\n",
        "Train for three epochs\n",
        "'''\n",
        "\n",
        "t_start = time.time()\n",
        "\n",
        "history = model.fit(datain_tr,\n",
        "                    dataou_tr,\n",
        "                    epochs           = 3,\n",
        "                    batch_size       = 128,\n",
        "                    verbose          = 1,\n",
        "                    shuffle          = True,\n",
        "                    validation_split = 0.05)\n",
        "\n",
        "t_end   = time.time()\n",
        "\n",
        "t_transfer_learning = t_end - t_start\n",
        "\n",
        "print('\\nTransfer learning training time: {:06.2f} sec'.format(t_transfer_learning))\n"
      ],
      "metadata": {
        "id": "UFzTkNY-eu0c",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Fine-tuning\n",
        "'''\n",
        "Unfreeze the base model and train the whole model.\n",
        "'''\n",
        "model_base.trainable = True\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(0.00001),\n",
        "              loss      = 'categorical_crossentropy',\n",
        "              metrics   = ['accuracy'])\n",
        "\n",
        "print('summary of model_DenseNet121:\\n')\n",
        "model_base.summary()\n",
        "\n",
        "print('summary of model:\\n')\n",
        "model.summary()\n",
        "\n",
        "'''\n",
        "Train for two epochs.\n",
        "'''\n",
        "\n",
        "t_start = time.time()\n",
        "\n",
        "history = model.fit(datain_tr,\n",
        "                    dataou_tr,\n",
        "                    epochs           = 2,\n",
        "                    batch_size       = 128,\n",
        "                    verbose          = 1,\n",
        "                    shuffle          = True,\n",
        "                    validation_split = 0.05)\n",
        "\n",
        "t_end   = time.time()\n",
        "\n",
        "t_fine_tuning = t_end - t_start\n",
        "\n",
        "print('\\nFine-tuning training time: {:06.2f} sec'.format(t_fine_tuning))\n"
      ],
      "metadata": {
        "id": "5qrDzPCUezUI",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Compute testing accuracy\n",
        "_, accuracy_te = model.evaluate(datain_te,\n",
        "                                dataou_te,\n",
        "                                batch_size = 128)\n",
        "\n",
        "print('\\nTotal Training time: {:06.2f} sec'.format(t_transfer_learning + t_fine_tuning))\n",
        "print('\\nTesting acuuracy: {:05.2f}%'.format(accuracy_te * 100))"
      ],
      "metadata": {
        "id": "kew4FGaWWJJy",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Clean up memory\n",
        "%reset"
      ],
      "metadata": {
        "id": "zySh2KaiYD3O",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ***Reminder: in all these practices, we did not touch the remaining, assumed to be unlabeled, training input data.***"
      ],
      "metadata": {
        "id": "QbG1ozHsEdKO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lecture 5: Labeling Challenges**\n",
        "\n",
        "In this lecture, you learned about:\n",
        "\n",
        "1. Challenges of labeling large repositories.\n",
        "2. Supervised labeling implementation.\n",
        "\n",
        "> ***In the following lecture, we will talk about \"Self-Supervised Learning (SSL).\"***"
      ],
      "metadata": {
        "id": "OWML14xDnq7v"
      }
    }
  ]
}